{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "661b1e98-2e88-427c-96d2-e5f58473aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from groq import Groq\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b029bbd1-63b8-4f0a-bbb9-58d4bce7fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open dataset and store it as a JSON object\n",
    "with open('../GSM-IC/GSM-IC_mstep.json', 'r') as file:\n",
    "    questions = json.load(file)\n",
    "with open('../GSM-IC/GSM-IC_2step.json', 'r') as file:\n",
    "    questions2 = json.load(file)\n",
    "    #initialize the Groq client. This allows us to query Llama3 (or another model) from my Groq account\n",
    "#todo: store the api_key in a secure way!\n",
    "# client = Groq(\n",
    "    # api_key=os.environ.get(\"GROQ_API_KEY\")\n",
    "    # api_key='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'\n",
    "# )\n",
    "client = OpenAI(api_key=open(\"api.txt\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5c3b26b-f5f1-4967-bc8a-9a4405c49dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_questions = []\n",
    "all_questions.extend(questions2)\n",
    "all_questions.extend(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c911366-dff7-4a87-bf5e-b1cdef5b0aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: 1. answer_prompt is the current way of forcing the model to output its answer in predictable format. Find a better way to extract the numerical answer from the model's output. (maybe: require JSON output)\n",
    "\n",
    "#todo: 2. clean up the answer. Ex. remove $, %, inches, etc. \n",
    "\n",
    "def single_query_distractor_test(query):\n",
    "    \"\"\"\n",
    "    query the model with a single question\n",
    "    input: what you would type in the chat box to ask the model a question\n",
    "    output: the model's output in response to your query \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    answer_prompt='The last sentence of your response must be in the form \"The answer is [your answer]\". Include \"irrelevant\" in your response if there is any irrelevant information in the question.'\n",
    "    chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query + answer_prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    )\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    return response \n",
    "\n",
    "def single_query(query):\n",
    "    \"\"\"\n",
    "    query the model with a single question\n",
    "    input: what you would type in the chat box to ask the model a question\n",
    "    output: the model's output in response to your query \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    answer_prompt='The last sentence of your response must be in the form \"The answer is [your answer]\".'\n",
    "    chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query + answer_prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    )\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    return response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483e3f66-12ff-4451-85fb-d0280fafc261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [05:28<00:00,  1.52it/s]\n",
      "100%|█████████████████████████████████████████| 500/500 [07:17<00:00,  1.14it/s]\n",
      "100%|█████████████████████████████████████████| 500/500 [07:04<00:00,  1.18it/s]\n",
      "100%|█████████████████████████████████████████| 500/500 [08:26<00:00,  1.01s/it]\n",
      " 97%|███████████████████████████████████████▊ | 485/500 [10:18<00:19,  1.28s/it]"
     ]
    }
   ],
   "source": [
    "import tqdm, pickle\n",
    "\n",
    "def run_queries(attribute, fn, outfile, n):\n",
    "    answers = []\n",
    "    for steps in [2, 3, 4, 5, 6]:\n",
    "        qk = [i for i in all_questions if i['n_steps'] == steps]\n",
    "        for q in tqdm.tqdm(qk[:n]):\n",
    "            answers.append(fn(q[attribute]))\n",
    "    f=open(outfile, \"wb\")\n",
    "    pickle.dump(answers, f)\n",
    "    print(\"[+] saved to\", outfile)\n",
    "\n",
    "# run_queries('original_question', single_query_distractor_test, 'FINAL35-orig-distractor.obj', 500)\n",
    "# run_queries('new_question', single_query_distractor_test, 'FINAL35-new-distractor.obj', 500)\n",
    "run_queries('original_question', single_query, 'FINAL35-orig2.obj', 500)\n",
    "run_queries('new_question', single_query, 'FINAL35-new2.obj', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e5cd6-9b9e-4c1f-9d40-6f9035a0878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_queries('original_question', single_query_distractor_test, 'FINAL35-orig-distractor-2.obj', 500)\n",
    "run_queries('new_question', single_query_distractor_test, 'FINAL35-new-distractor-2.obj', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "726d8080-bbee-4334-b067-0bc45718bce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23832"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = get_answers(questions2, question_type='original_question', num_questions=500)\n",
    "answers_steps = []\n",
    "for steps in [3, 4, 5, 6]:\n",
    "    answers_steps.append(get_answers([i for i in questions if i['n_steps'] == steps], question_type='original_question', num_questions=500))\n",
    "answers_new = get_answers(questions2, question_type='new_question', num_questions=500)\n",
    "answers_steps_new = []\n",
    "for steps in [3, 4, 5, 6]:\n",
    "    answers_steps_new.append(get_answers([i for i in questions if i['n_steps'] == steps], question_type='new_question', num_questions=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d42b4c00-7411-4658-9999-fc092fcc017b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_question': 'Monica is a teacher. She has 6 classes per day. The first class has 20 students. The second and third classes have 25 students. Her fourth class has half as many as her first class. Her fifth and sixth classes have 28 students. How many students does Monica see each day?',\n",
       " 'answer': '136',\n",
       " 'new_question': \"Monica is a teacher. She has 6 classes per day. The first class has 20 students. The second and third classes have 25 students. Her fourth class has half as many as her first class. Her fifth and sixth classes have 28 students. The height of Monica's neighbor is 30 feet. How many students does Monica see each day?\",\n",
       " 'n_steps': 3,\n",
       " 'role': \"Monica's neighbor\",\n",
       " 'number': '30',\n",
       " 'sentence_template': 'The height of {role} is {number} feet.',\n",
       " 'role_label': 'overlapped',\n",
       " 'number_label': 'in_range',\n",
       " 'sentence_label': 'out_topic'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = questions[100]\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ddf2d04-e782-4aad-aac9-cc308de8ded4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"answer\": \"166 students\",\\n  \"thoughts\": \"First class: 20 students, Second class: 25 students, Third class: 25 students, Fourth class: 10 students, Fifth class: 28 students, Sixth class: 28 students. Total students per day: 20 + 25 + 25 + 10 + 28 + 28 = 166 students.\",\\n  \"has_distractor\": false\\n}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_query(q['original_question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "040eac20-0b0f-408e-903d-208e5543fce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"answer\": \"166 students\",\\n  \"thoughts\": \"Monica sees 20 students in the first class, 25 students in the second class, 25 students in the third class, 10 students in the fourth class, and 28 students in the fifth and sixth classes each. Adding all these up, Monica sees a total of 20 + 25 + 25 + 10 + 28 + 28 = 166 students each day.\",\\n  \"has_distractor\": true\\n}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_query(q['new_question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f89a32d-e8cc-40ec-aaba-4b8fb3887932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'136'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
